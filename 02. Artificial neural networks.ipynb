{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10f3efba-2a4d-498a-b784-937dcbbcc8a0",
   "metadata": {},
   "source": [
    "## 1. Activation functions.\n",
    "***\n",
    "\n",
    "!['activation'](activation_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8871e8a-5541-48a3-94b2-37733c542718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d9f0063-946d-406e-8995-64c75f9f587b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9696, 0.7527])\n"
     ]
    }
   ],
   "source": [
    "#The neural net blueprint is implemented with pytorch below.\n",
    "input_layer = torch.tensor([2., 1.])\n",
    "weight_1 = torch.tensor([[0.45, 0.32], [-0.12, 0.29]])\n",
    "\n",
    "hidden_layer = torch.matmul(input_layer, weight_1)\n",
    "\n",
    "weight_2 = torch.tensor([[0.48, -0.12], [0.64, 0.91]])\n",
    "output_layer = torch.matmul(hidden_layer, weight_2)\n",
    "print(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3f9549-2ab0-4099-83e5-6d46db999064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4208, 0.2372],\n",
      "        [0.1280, 0.2783]])\n"
     ]
    }
   ],
   "source": [
    "weight = torch.matmul(weight_1, weight_2)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86579163-4775-4daa-86be-bea6fe2ea621",
   "metadata": {},
   "source": [
    "\n",
    "#### To compute a layer, you need to multiply the previous layer by the weights of connections between the layers. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47324d3-3f45-4d22-a303-25b156e75300",
   "metadata": {},
   "source": [
    "### 1.1 ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ba3dee-e703-44d5-bf70-9dc61d90ab77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 0.])\n",
      "tensor([[2.0000, 0.0000],\n",
      "        [1.2000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "\n",
    "tensor_1 = torch.tensor([2., -4.])\n",
    "print(relu(tensor_1))\n",
    "\n",
    "tensor_2 = torch.tensor([[2., -4.], \n",
    "                        [1.2, 0.]])\n",
    "print(relu(tensor_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a25861b0-7cc3-4767-a8d4-b8141632d3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.1240, 4.1571])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate ReLU activation function as relu\n",
    "relu = nn.ReLU()\n",
    "\n",
    "input_layer = torch.rand(4)\n",
    "# Initialize weight_1 and weight_2 with random numbers\n",
    "weight_1 = torch.rand(4, 6)\n",
    "weight_2 = torch.rand(6, 2)\n",
    "\n",
    "# Multiply input_layer with weight_1\n",
    "hidden_1 = torch.matmul(input_layer, weight_1)\n",
    "\n",
    "# Apply ReLU activation function over hidden_1 and multiply with weight_2\n",
    "hidden_1_activated = relu(hidden_1)\n",
    "print(torch.matmul(hidden_1_activated, weight_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f6725-6817-43bd-a23a-9b51cfff3d09",
   "metadata": {},
   "source": [
    "## 2. Loss functions.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec674dec-0c91-4a77-ad53-13567cdfd044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0117)\n"
     ]
    }
   ],
   "source": [
    "#Initialize the scores and ground truth\n",
    "logits = torch.tensor([[-1.2, 0.12, 4.8]])\n",
    "ground_truth = torch.tensor([2])\n",
    "\n",
    "#Instantiate the cross-entropy loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Compute and print the loss.\n",
    "loss = criterion(logits, ground_truth)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc7ba6e-b366-4648-824e-88533ccc6618",
   "metadata": {},
   "source": [
    "## 3. Preparing a dataset in Pytorch.\n",
    "\n",
    "#### We'll use `MNIST` and `CIFAR-10` datasets.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99eeedce-0f2b-449c-9e14-c56fd140e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a04f06-2403-4cf5-8994-0e94ba5fd820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the transformation of images to torch tensors.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #Standardize the images in each channel. (Mean, Std.Dev)\n",
    "    transforms.Normalize((0.4914, 0.48216, 0.44653),\n",
    "                         (0.24703, 0.24349, 0.26159))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c6d01ee-ac54-4670-aa1c-583dce8028f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Obtain the dataset.\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, \n",
    "                                       download = True, transform = transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, \n",
    "                                      download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09bf62a0-aa12-43db-ae20-6e8076d06f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build trainloader and testloader to get the dataset ready for Pytorch.\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 32, \n",
    "                                         shuffle = True, num_workers = 4)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 32, \n",
    "                                        shuffle = False, num_workers = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf9b68a1-9a88-47a3-8e55-e79b255cf88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "<torch.utils.data.sampler.RandomSampler object at 0x7f9ef2581bb0>\n"
     ]
    }
   ],
   "source": [
    "#Inspect the batch size.\n",
    "print(testloader.batch_size)\n",
    "\n",
    "#Inspact the type of random sampler.\n",
    "print(trainloader.sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d3142a-5d6b-4469-b787-85b6be394b6c",
   "metadata": {},
   "source": [
    "## 4. Training neural nets.\n",
    "***\n",
    "\n",
    "#### The procedure for training a neural net looping over the dataset while:\n",
    "- Do a forward pass.\n",
    "- Calculate the loss function.\n",
    "- Calculate the gradients.\n",
    "- Change the weights based on the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3e66fa9-9ebf-4d71-9f89-05858817c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcff0f4e-f72f-4c8a-acc6-9f7714e4942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 500) #Input shape same as the CIFAR-10 dataset shape.\n",
    "        self.fc2 = nn.Linear(500, 10) #500 input nodes and 10 output nodes.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934357de-a94b-432d-a7fd-f8bcc98bded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the network, the loss function and the optimizer.\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 3e-4)\n",
    "\n",
    "for epoch in range(10): #Loop over the dataset multiple times.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        #Get the inputs.\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1, 32 * 32 * 3) #Put images into vectors\n",
    "        \n",
    "        #Zero the parameter gradients.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60215b7-22d3-46dd-aed6-441196d14804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform inference.\n",
    "correct, total = 0, 0\n",
    "predictions = []\n",
    "net.eval() #Evaluation mode.\n",
    "\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.view(-1, 32 * 32 * 3)\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions.append(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    \n",
    "print('The test set accuracy is: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
